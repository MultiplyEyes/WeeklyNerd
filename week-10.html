<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Weekly Nerd - Jan Matthijs Stokroos</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div>
        <div class="wrapper">
            <div class="Matthijs">
                <img src="fisherman.svg" alt="">
            </div>
            <div class="blue">

                <div class="dropdown">
                    <p class="dropbtn">Weekly Nerd</p>
                    <a href="week-1.html" class="dropdown-content">Stop using JS</a>
                    <a href="week-2.html" class="dropdown-content">Unavailable</a>
                    <a href="week-3.html" class="dropdown-content">GSAP</a>
                    <a href="week-4.html" class="dropdown-content">Imperative and Declarative</a>
                    <a href="week-5.html" class="dropdown-content">Hackers Everwhere</a>
                    <a href="week-6.html" class="dropdown-content">Kassa's van Niels Leenheer</a>
                    <a href="week-7.html" class="dropdown-content">IDEA11Y</a>
                    <a href="week-8.html" class="dropdown-content">Outside The Box accesibiaty</a>
                </div>

                <div class="dropdown">
                    <p href="week-9.html" class="dropbtn">Weekly Nerd 2</p>
                    <a href="week-10.html" class="dropdown-content">IO Digital - Digital Voice</a>
                    <a href="week-11.html" class="dropdown-content">IO Digital - Unethical Twitter</a>
                    <a href="week-12.html" class="dropdown-content">IO Digital - Testing</a>
                    <a href="week-13.html" class="dropdown-content">Q42 - SenseMath</a>
                    <a href="week-14.html" class="dropdown-content">Q42 - Ocuae Mundi</a>
                    <a href="week-15.html" class="dropdown-content">Digitale Toegankelijk</a>
                    <a href="week-16.html" class="dropdown-content">Unwrapping web design</a>
                    <a href="week-17.html" class="dropdown-content">Internet Polatics</a>
                </div>

                <div class="dropdown">
                    <p class="dropbtn">Leerdoelen</p>
                    <a href="leerdoel-CSS.html" class="dropdown-content">CSS Art</a>
                    <a href="leerdoel-Worden.html" class="dropdown-content">Beter Verworden</a>
                    <a href="leerdoel-Vragen.html" class="dropdown-content">Hulp Vragen</a>
                    <a href="leerdoel-java.html" class="dropdown-content">Javascript</a>
                </div>

                <div class="dropdown">
                    <p class="dropbtn">Opdrachten</p>
                    <a href="WFAF.html" class="dropdown-content">WAFS</a>
                    <a href="CSS.html" class="dropdown-content">CSS Groundhog Day</a>
                    <a href="NS.html" class="dropdown-content">BT NS</a>
                    <a href="Hack.html" class="dropdown-content">Hackathon</a>
                    <a href="HCD.html" class="dropdown-content">HCD Darice</a>
                    <a href="API.html" class="dropdown-content">API Monster Hunter</a>
                    <a href="Meesterproef.html" class="dropdown-content">Meesterproef</a>
                </div>
            </div>
            <div class="fish">
                <h3>IO Digital AI voice</h3>
                <h4>Dave Bitter</h4>
                <p>Laika is een AI-tiener die uitsluitend is opgevoed door sociale media. Dit heeft geleid tot veel
                    negatieve effecten, zoals depressie en een kort concentratievermogen.</p>
                <p><strong>De opkomst van AI-aangedreven steminterfaces</strong></p>
                <p> Vroeger moest je via Google meerdere
                    pagina’s doorzoeken om informatie te vinden. Nu hebben we ChatGPT, waarmee je alles kunt vragen in
                    een natuurlijk gesprek. Een voorbeeld hiervan is Presiparrot, een project van Dave dat opnieuw tot
                    leven is gebracht dankzij AI.</p>
                <p><strong>Geschiedenis van spraakherkenning</strong></p>
                <ul>
                    <li>
                        <p>In de jaren 1950-1960 werd spraakherkenning ontdekt.</p>
                    </li>
                    <li>
                        <p>In de jaren 1960-1970 werd het verbeterd.</p>
                    </li>
                    <li>
                        <p>Rond 1990 werd het vaker gebruikt door consumenten.</p>
                    </li>
                    <li>
                        <p>In de jaren 2000 deed Google er onderzoek naar.</p>
                    </li>
                    <li>
                        <p>In de jaren 2010 kregen we Siri en Alexa.</p>
                    </li>
                    <li>
                        <p>In 2020 werd spraak naar tekst (voice-to-transcript) standaard in tools zoals Microsoft
                            Teams.</p>
                    </li>
                    <li>
                        <p>Tegenwoordig kan spraak direct gekoppeld worden aan systemen zoals ChatGPT.</p>
                    </li>
                </ul>
                <p><strong>Speech API </strong></p> 
                <p>API wordt gebruikt in moderne browsers.<br />Het systeem kan herkennen wat je zegt en verbetert naarmate je langer praat.<br />Op Daves laptop werkt dit momenteel al voor meerdere talen, maar je moet handmatig schakelen tussen talen.</p>
                <p><strong>Speech Synthesis </strong></p>
                <p>Dit is de ‘output voice’ – oftewel, de stem die de AI gebruikt om terug te praten. De kwaliteit van de stem is nog niet perfect en klinkt soms onnatuurlijk.</p>
                <p><strong>AI als gesprekspartner </strong></p>
                <p>AI kan nadenken over wat het terugzegt. Je kunt het een persoonlijkheid geven en context meegeven. Het kan ook "luisteren" en reageren zonder iets actiefs te doen – dus gewoon aanwezig zijn in een gesprek.</p>

                <p><strong>“When in doubt, more AI”</strong></p>
                <p>Er bestaan betere voicemodulators die natuurlijker klinken, maar ze hebben vaak een zware vertraging. Dit breekt de illusie van een natuurlijk gesprek. Er is een oplossing voor dit probleem: je kunt de stem alvast laten afspelen terwijl de informatie wordt opgehaald (volgens mij werkt dit zo).</p>
                <h3>Reflectie</h3>
                <p>
                    Deze presentatie was heel interessant en ik heb veel geleerd over hoe AI kan worden gebruikt om
                    spraakherkenning en spraaksynthese te verbeteren.
                </p>
            </div>
        </div>
    </div>
</body>

</html>